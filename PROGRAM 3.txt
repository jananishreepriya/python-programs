import math 

class Point: 
    def __init__(self, a, b, c): 
        self.x = a 
        self.y = b 
        self.z = c 

    def distance_from_origin(self): 
        return math.sqrt(self.x ** 2 + self.y ** 2 + self.z ** 2)

    def distance(self, point2): 
        x_diff = self.x - point2.x 
        y_diff = self.y - point2.y 
        z_diff = self.z - point2.z 
        dist = math.sqrt(x_diff ** 2 + y_diff ** 2 + z_diff ** 2) 
        return dist 

# Taking inputs for the coordinates of points P1 and P2
x1, y1, z1 = map(int, input("Enter the coordinates of the first point P1 (x1, y1, z1): ").split()) 
x2, y2, z2 = map(int, input("Enter the coordinates of the second point P2 (x2, y2, z2): ").split()) 

# P1 and P2 are objects of the Point class 
p1 = Point(x1, y1, z1) 
p2 = Point(x2, y2, z2) 

# Printing the calculated distances
print('Distance from origin to P1:', p1.distance_from_origin()) 
print('Distance from origin to P2:', p2.distance_from_origin()) 
print('Distance from P1 to P2:', p1.distance(p2)) 
